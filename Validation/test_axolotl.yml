datasets:
    path: 'path/to/your/test/dataset'
    type: 'your_dataset_type'  

sequence_len: 4096
batch_size: 1
output_dir: 'outputs/'
val_set_size: 0
train_batch_size : 8
micro_batch_size: 8
do_causal_lm_eval: True
#use_wandb: True
#eval_table_size: 100
eval_causal_lm_metrics: ["perplexity", "sacrebleu", "comet", "ter", chrf]
device: 'cuda'

do_train: false
do_eval: true
evaluation_strategy: "steps"
eval_steps: 100
sample_packing: false
eval_sample_packing: true


pad_to_sequence_len: true

gradient_accumulation_steps: 4
micro_batch_size: 2
num_epochs: 1
optimizer: adamw_bnb_8bit
lr_scheduler: cosine
learning_rate: 0.0002